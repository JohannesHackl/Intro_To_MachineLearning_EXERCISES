{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e015e3e",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage\n",
    "import util_affine\n",
    "\n",
    "#### loading data\n",
    "points_source = np.load('data/points_source.npy')\n",
    "points_destination = np.load('data/points_destination.npy')\n",
    "\n",
    "\n",
    "\n",
    "def build_target_vector(dst_points):\n",
    "    # dst_points: array of shape (N, 2) with rows [x'_i, y'_i]\n",
    "    return dst_points.flatten()\n",
    "\n",
    "def build_affine_design_matrix(src_points):\n",
    "    # src_points: array of shape (N, 2) with rows [x_i, y_i]\n",
    "    x = src_points[:, 0]\n",
    "    y = src_points[:, 1]\n",
    "\n",
    "    rows = []\n",
    "    for xi, yi in zip(x, y):\n",
    "        # Row for x' equation\n",
    "        rows.append([xi, yi, 1, 0, 0, 0])\n",
    "        # Row for y' equation\n",
    "        rows.append([0, 0, 0, xi, yi, 1])\n",
    "    A = np.array(rows)\n",
    "    return A\n",
    "\n",
    "def estimate_affine_parameters(A, b):\n",
    "    # Solve using least squares\n",
    "    w = np.linalg.inv(A.T @ A) @ A.T @ b\n",
    "    return w  # shape (6,)\n",
    "\n",
    "def build_affine_matrix(w):\n",
    "    T = np.array([\n",
    "        [w[0], w[1], w[2]],\n",
    "        [w[3], w[4], w[5]],\n",
    "        [0,    0,    1   ]\n",
    "    ])\n",
    "    return T\n",
    "\n",
    "\n",
    "\n",
    "### affine tranformation creation\n",
    "\n",
    "def calc_affine(points_source, points_destination):\n",
    "    \"\"\"\n",
    "    Estimate the affine transformation matrix using the corresponding points pairs\n",
    "    \n",
    "    Args:\n",
    "        points_source: Points in the video \n",
    "        points_destination: Corresponding points in the map\n",
    "\n",
    "    Returns:\n",
    "        The affine matrix T\n",
    "    \"\"\"\n",
    "\n",
    "    A = build_affine_design_matrix(points_source)\n",
    "    b = build_target_vector(points_destination)\n",
    "    w = estimate_affine_parameters(A, b)\n",
    "    T = build_affine_matrix(w)\n",
    "\n",
    "    print(\"Design matrix A:\\n\", A)\n",
    "    print(\"\\nTarget vector b:\\n\", b)\n",
    "    print(\"\\nParameters w:\\n\", w)\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "T = calc_affine(points_source, points_destination)\n",
    "print('\\nThe affine Trasformation Matrix:\\n', T)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads the tracking data.\"\"\"\n",
    "    filename = \"data/trackingdata.dat\"\n",
    "    data = np.loadtxt(filename)\n",
    "    data = {\"body\": data[:, :4], \"legs\": data[:, 4:8], \"all\": data[:, 8:]}\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "### Load data \n",
    "data = load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859a77f",
   "metadata": {},
   "source": [
    "# Extract frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_video_frames(video_path, max_frames=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert from BGR (OpenCV default) to RGB (matplotlib expects RGB)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "        count += 1\n",
    "        if max_frames and count >= max_frames:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "video_frames = load_video_frames(\"data/ITUStudent.mov\")  # limit if needed\n",
    "# print(video_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7108d",
   "metadata": {},
   "source": [
    "# Export map trace as GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "def animate_map(tracking_data, T, fps=10):\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    map_img = plt.imread(\"data/ITUMap.png\")\n",
    "    ax.imshow(map_img)\n",
    "    ax.set_title(\"Projected center on ITU Map\")\n",
    "\n",
    "    xs, ys = [], []\n",
    "    point, = ax.plot([], [], 'ro', label=\"current position\")\n",
    "    trace, = ax.plot([], [], 'g-', alpha=0.7, label=\"trajectory\")\n",
    "\n",
    "    n_frames = tracking_data['all'].shape[0]\n",
    "\n",
    "    def update(i):\n",
    "        # center of \"all\" bbox\n",
    "        x1,y1,x2,y2 = tracking_data['all'][i]\n",
    "        cx, cy = (x1+x2)/2, (y1+y2)/2\n",
    "\n",
    "        # project to map\n",
    "        proj = T @ np.array([cx, cy, 1])\n",
    "        proj /= proj[2]\n",
    "\n",
    "        xs.append(proj[0])\n",
    "        ys.append(proj[1])\n",
    "\n",
    "        point.set_data([proj[0]], [proj[1]])\n",
    "        trace.set_data(xs, ys)\n",
    "        return point, trace\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update, frames=n_frames,\n",
    "        interval=1000/fps, blit=True, repeat=False\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return ani\n",
    "\n",
    "ani = animate_map(data, T, fps=15)\n",
    "\n",
    "# # Save as mp4 (requires ffmpeg installed)\n",
    "# ani.save(\"trajectory.mp4\", writer=\"ffmpeg\", fps=15)\n",
    "\n",
    "# Or save as gif (requires imagemagick or pillow)\n",
    "# ani.save(\"map_trajectory.gif\", writer=\"pillow\", fps=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab792eeb",
   "metadata": {},
   "source": [
    "# Export video and map trace as GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(\"Frames:\", cv2.VideoCapture(\"data/ITUStudent.mov\").get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def animate_video_and_map(video_frames, tracking_data, part, T, fps=10, outname=\"video_and_map.gif\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    # --- Left: video plane ---\n",
    "    im_video = ax[0].imshow(video_frames[0])\n",
    "    ax[0].set_title(\"Video with bounding boxes\")\n",
    "\n",
    "    colors = {'body':'r','legs':'b','all':'g'}\n",
    "    rects = {b_part: patches.Rectangle((0,0),1,1,fill=False,edgecolor=color,linewidth=2)\n",
    "             for b_part,color in colors.items()}\n",
    "    for rect in rects.values():\n",
    "        ax[0].add_patch(rect)\n",
    "    center_point, = ax[0].plot([], [], 'yo')\n",
    "\n",
    "    # --- Right: map plane ---\n",
    "    map_img = plt.imread(\"data/ITUMap.png\")\n",
    "    im_map = ax[1].imshow(map_img)\n",
    "    ax[1].set_title(\"Projected center on ITU Map\")\n",
    "    proj_point, = ax[1].plot([], [], 'ro')\n",
    "    trace, = ax[1].plot([], [], 'g-', alpha=0.7)\n",
    "\n",
    "    xs, ys = [], []\n",
    "    n_frames = min(len(video_frames), tracking_data['all'].shape[0])\n",
    "\n",
    "    def update(i):\n",
    "        # Update video frame\n",
    "        im_video.set_data(video_frames[i])\n",
    "\n",
    "        # Update bounding boxes\n",
    "        for b_part, rect in rects.items():\n",
    "            x1,y1,x2,y2 = tracking_data[b_part][i]\n",
    "            rect.set_xy((x1,y1))\n",
    "            rect.set_width(x2-x1)\n",
    "            rect.set_height(y2-y1)\n",
    "\n",
    "        # Center point\n",
    "        x1,y1,x2,y2 = tracking_data['all'][i]\n",
    "        cx, cy = (x1+x2)/2, (y1+y2)/2\n",
    "        center_point.set_data([cx],[cy])\n",
    "\n",
    "        # Project to map\n",
    "        proj = T @ np.array([cx, cy, 1])\n",
    "        proj /= proj[2]\n",
    "        xs.append(proj[0]); ys.append(proj[1])\n",
    "        proj_point.set_data([proj[0]], [proj[1]])\n",
    "        trace.set_data(xs, ys)\n",
    "\n",
    "        return [im_video, center_point, proj_point, trace] + list(rects.values())\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=n_frames,\n",
    "                                  interval=1000/fps, blit=True, repeat=False)\n",
    "\n",
    "    # Save as GIF\n",
    "    ani.save(outname, writer=\"pillow\", fps=fps)\n",
    "    # plt.close(fig)\n",
    "    print(f\"Saved combined animation to {outname}\")\n",
    "\n",
    "# animate_video_and_map(video_frames, data, part, T, fps=15, outname=\"combined_videoMap.gif\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
